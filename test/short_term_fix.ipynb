{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os \n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.chdir(\"..\")\n",
    "from app.entities.chat import Chat, Survey, ProductReview\n",
    "from app.entities.enumerators import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "there_is_full_data = True\n",
    "\n",
    "full_data_path = \"./data/full_data.csv\"\n",
    "chat_file = \"./data/rnr_chat_w_transcript.csv\"\n",
    "agent_trans_file = \"./data/agent_transcript_topics.csv\"\n",
    "customer_trans_file = \"./data/customer_transcript_topics.csv\"\n",
    "survey_file = \"./data/RnR PCS Survey 2021-10-08.csv\"\n",
    "product_file = \"./data/RnR Product Reviews 2021-10-08.csv\"\n",
    "topic_file = \"./data/Rocks_N_Ropes_Chat_2022-06-21v2.csv\"\n",
    "date_dim_file = \"./data/date_dim.csv\"\n",
    "scenarios_file = \"./data/scenarios.csv\"\n",
    "customer_file = \"./data/customers.csv\"\n",
    "product_customer_file = \"./data/product_review_customers.csv\"\n",
    "agent_file = \"./data/agents.csv\"\n",
    "products_file = \"./data/products.csv\"\n",
    "text_builders_file = \"./data/text_drivers_2.xlsx\"\n",
    "\n",
    "# read in data\n",
    "chats = pd.read_csv(chat_file)\n",
    "surveys = pd.read_csv(survey_file)\n",
    "product_reviews = pd.read_csv(product_file) \n",
    "topics = pd.read_csv(topic_file)\n",
    "agent_trans = pd.read_csv(agent_trans_file)\n",
    "customer_trans = pd.read_csv(customer_trans_file)\n",
    "scenarios = pd.read_csv(scenarios_file)\n",
    "customers = pd.read_csv(customer_file)\n",
    "agents = pd.read_csv(agent_file)\n",
    "products = pd.read_csv(products_file)\n",
    "product_customers = pd.read_csv(product_customer_file)\n",
    "text_builders = pd.read_excel(text_builders_file,sheet_name=None)\n",
    "\n",
    "if there_is_full_data: \n",
    "    full_data = pd.read_csv(full_data_path,sep=\"|\")\n",
    "else: \n",
    "    full_data = pd.concat([customers]*10)\n",
    "\n",
    "    # add Contact Type\n",
    "    full_data[\"contact_type\"] = full_data.apply(lambda x : ContactType.random_by_dist(proba=[.0858,.1012,.1284,.6347,.0499]).name, axis =1)\n",
    "    full_data[\"product_name\"] = full_data.apply(lambda x : Product.random_by_dist(proba=[0.053,0.111,0.102,0.085,0.054,0.027,0.074,0.058,0.017,0.049,0.057,0.042,0.057,0.051,0.035,0.010,0.047,0.063,0.008]).name, axis =1)\n",
    "\n",
    "    # add new id\n",
    "    full_data.insert(0,\"new_chat_id\", range(1,1 + len(full_data)))\n",
    "    full_data.shape\n",
    "    full_data.to_csv(\"./data/full_data.csv\",index=False,sep=\"|\")\n",
    "\n",
    "# remove index becauase I forgot index = false\n",
    "agent_trans = agent_trans.iloc[:,1:]\n",
    "customer_trans = customer_trans.iloc[:,1:]\n",
    "chats = chats.iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(task, tokenizer, model):\n",
    "    # just used what is in memoroy already\n",
    "    input_ids = tokenizer.encode(task, return_tensors='pt')\n",
    "    greedy_output = model.generate(input_ids, num_beams=7, no_repeat_ngram_size=2, min_length=50, max_length=100)\n",
    "    message = tokenizer.decode(greedy_output[0], skip_special_tokens=True)\n",
    "    return message\n",
    "\n",
    "def build_comment(topic_item, product, contact_type, tokenizer, model): \n",
    "    topic = topic_item.Topic.values[0]\n",
    "    keyword = topic_item.Keyword.values[0]\n",
    "    task = f\"summarize:{product} {topic} {keyword} {contact_type}\"\n",
    "    task = task.replace(\"_\",\" \")\n",
    "    message = generate_text(task=task, tokenizer=tokenizer, model=model)\n",
    "    return message\n",
    "\n",
    "def generate_random_date(start_date,end_date):\n",
    "    import datetime\n",
    "    import random\n",
    "\n",
    "    # time_between_dates = end_date - start_date\n",
    "    # days_between_dates = time_between_dates.days\n",
    "    random_number_of_days = random.randrange((end_date - start_date).days)\n",
    "    random_date = start_date + datetime.timedelta(days=random_number_of_days, hours=random.randrange(0,24),minutes=random.randrange(0,60), seconds=random.randrange(0,60))\n",
    "    return random_date.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "def comment_task(df,tokenizer,model): \n",
    "    df[\"new_comment\"] = df.apply(lambda x: build_comment(tops.sample(1), x.product_name,x.contact_type,tokenizer, model),axis=1)\n",
    "    return df\n",
    "\n",
    "def comment_build(x,s_df): \n",
    "    # filter \n",
    "    filtered = s_df[(s_df[\"min\"] <= x.survey_score) & (s_df[\"max\"] >= x.survey_score)].copy()\n",
    "    return filtered[\"response\"].sample(n=1).values[0]\n",
    "\n",
    "def comment_task_dumb(df,selection_df):\n",
    "\n",
    "    \"\"\"\n",
    "    What was my idea here? what was I trying to accomplish? \n",
    "    1. for each df : \n",
    "        based on product and contact type \n",
    "            select random text from text builder df \n",
    "\n",
    "    \"\"\"\n",
    "    df[\"new_comment\"] = df.apply(lambda x: comment_build(x,selection_df), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Story 1 adjusting sitedown Survey sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up text surveys\n",
    "topic_filter = [\"Errors\",\"Crashing\",\"Website Feedback-Negative\",\"Website-Broken Links/Pages\"]\n",
    "tops = topics[topics.Topic.isin(topic_filter)].copy()\n",
    "\n",
    "# filter for site down\n",
    "text_builders_survey = text_builders[\"site_down_cust_survey\"]\n",
    "text_builders_survey = text_builders_survey[text_builders_survey.type==\"site_down\"].copy()\n",
    "text_builders_survey[\"min\"] = text_builders_survey[\"survey range\"].apply(lambda x: int(x[0]))\n",
    "text_builders_survey[\"max\"] = text_builders_survey[\"survey range\"].apply(lambda x: int(x[2]))\n",
    "\n",
    "# just grab some preseeded surveys\n",
    "outtage_surveys = site_down_chats = chats[chats.site_down==1][[\"chat_number\",\"site_down_sentiment\",\"CustomerID\",\"m_agent_ID\"]]\n",
    "outtage_surveys[\"survey_score\"] = outtage_surveys.apply(lambda x : SurveyScore.random_by_dist(proba=[.2,.3,.1,.2,.2,0,0,0,0,0]).value, axis =1)\n",
    "\n",
    "# random comment \n",
    "outtage_surveys[\"new_comment\"] = outtage_surveys.apply(lambda x: comment_build(x,text_builders_survey), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    1843\n",
       "9           1346\n",
       "Neutral      496\n",
       "Name: site_down_sentiment, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outtage_surveys.site_down_sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag(score, sentiment):\n",
    "    if sentiment == \"9\":\n",
    "        return sentiment\n",
    "    if score < 5: \n",
    "        return \"Negative\"\n",
    "    elif score >= 5 and score <=6: \n",
    "        return \"Neutral\"\n",
    "    \n",
    "outtage_surveys[\"new_sentiment\"] = outtage_surveys.apply(lambda x: tag(x.survey_score, x.site_down_sentiment), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust customers \n",
    "outtage_surveys = outtage_surveys.merge(customers[[\"id\",\"first_name\",\"last_name\",\"email\",\"member_number\"]], how=\"left\",left_on=\"CustomerID\",right_on=\"id\")\n",
    "outtage_surveys[\"ContactName\"] = outtage_surveys.apply(lambda x: x.first_name.upper() + \" \" + x.last_name.upper(), axis=1)\n",
    "outtage_surveys = outtage_surveys.rename(columns={\n",
    "    \"email\":\"ContactEmail\"\n",
    "})\n",
    "\n",
    "outtage_surveys = outtage_surveys.drop(columns=[\"first_name\",\"last_name\",\"id\"])\n",
    "\n",
    "# adjust agents\n",
    "outtage_surveys = outtage_surveys.merge(agents[[\"id\",\"first_name\",\"last_name\",\"team_name\"]],how=\"left\",left_on=\"m_agent_ID\",right_on=\"id\")\n",
    "outtage_surveys[\"m_agent_name\"] = outtage_surveys.apply(lambda x: x.first_name + \" \" + x.last_name, axis=1)\n",
    "outtage_surveys = outtage_surveys.rename(columns={\n",
    "    \"team_name\":\"m_agent_team_ID\"\n",
    "})\n",
    "outtage_surveys = outtage_surveys.drop(columns=[\"first_name\",\"last_name\",\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outtage_surveys = outtage_surveys.drop(columns=[\"site_down_sentiment\"])\n",
    "outtage_survesy = outtage_surveys.rename(columns={\"new_commnet\":\"overall_experience_comment\",\"new_sentiment\":\"site_down_sentiment\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "outtage_surveys[\"TransactionDateUTC\"] = outtage_surveys.apply(lambda x: generate_random_date(start_date=datetime.datetime(2022,4,4),end_date=datetime.datetime(2022,4,6)), axis=1)\n",
    "outtage_surveys[\"ResponseReceivedDateUTC\"] = outtage_surveys.apply(lambda x: generate_random_date(start_date=datetime.datetime(2022,4,6),end_date=datetime.datetime(2022,4,30)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "outtage_surveys.to_csv(\"./data/us1_final_site_down_surveys.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Story 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('.dev': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed0cf586b1e59d818733435ee7616ee74ffcd2e2089d21a9a6d62947d44d89e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
